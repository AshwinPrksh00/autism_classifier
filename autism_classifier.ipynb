{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_args = dict(rescale=1./255, validation_split=.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = ('./dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2352 images belonging to 2 classes.\n",
      "Found 588 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "bag_train = tf.keras.preprocessing.image.ImageDataGenerator(**data_args)\n",
    "\n",
    "train_gen = bag_train.flow_from_directory(\n",
    "img_dir,\n",
    "subset=\"training\",\n",
    "shuffle=True,\n",
    "target_size=(224, 224))\n",
    "\n",
    "\n",
    "bag_val = tf.keras.preprocessing.image.ImageDataGenerator(**data_args)\n",
    "\n",
    "val_gen = bag_val.flow_from_directory(\n",
    "img_dir,\n",
    "subset=\"validation\",\n",
    "shuffle=True,\n",
    "target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 224, 224, 3), (32, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for image_batch, label_batch in train_gen:\n",
    "    break\n",
    "image_batch.shape, label_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Autistic': 0, 'Non_Autistic': 1}\n"
     ]
    }
   ],
   "source": [
    "print (train_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer (KerasLayer)    (None, 1280)              2257984   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 2562      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,260,546\n",
      "Trainable params: 2,562\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.Sequential([\n",
    " hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\", \n",
    " output_shape=[1280],\n",
    " trainable=False),\n",
    " tf.keras.layers.Dropout(0.4),\n",
    " tf.keras.layers.Dense(train_gen.num_classes, activation='softmax')\n",
    "])\n",
    "base_model.build([None, 224, 224, 3])\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theja\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "base_model.compile(\n",
    " optimizer=optimizer,\n",
    " loss= 'categorical_crossentropy',\n",
    " metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "def calculate_spe(y):\n",
    "  return int(math.ceil((1. * y) / 32))\n",
    "steps_per_epoch = calculate_spe(2800)\n",
    "steps_per_epoch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "74/74 [==============================] - 52s 698ms/step - loss: 0.3451 - accuracy: 0.8427 - val_loss: 0.6573 - val_accuracy: 0.7126\n",
      "Epoch 2/20\n",
      "74/74 [==============================] - 49s 666ms/step - loss: 0.3386 - accuracy: 0.8486 - val_loss: 0.6068 - val_accuracy: 0.7194\n",
      "Epoch 3/20\n",
      "74/74 [==============================] - 54s 725ms/step - loss: 0.3543 - accuracy: 0.8423 - val_loss: 0.5957 - val_accuracy: 0.7211\n",
      "Epoch 4/20\n",
      "74/74 [==============================] - 54s 724ms/step - loss: 0.3484 - accuracy: 0.8495 - val_loss: 0.6223 - val_accuracy: 0.7313\n",
      "Epoch 5/20\n",
      "74/74 [==============================] - 56s 758ms/step - loss: 0.3476 - accuracy: 0.8389 - val_loss: 0.6200 - val_accuracy: 0.7313\n",
      "Epoch 6/20\n",
      "74/74 [==============================] - 53s 724ms/step - loss: 0.3425 - accuracy: 0.8512 - val_loss: 0.5993 - val_accuracy: 0.7245\n",
      "Epoch 7/20\n",
      "74/74 [==============================] - 54s 729ms/step - loss: 0.3512 - accuracy: 0.8380 - val_loss: 0.6068 - val_accuracy: 0.7058\n",
      "Epoch 8/20\n",
      "74/74 [==============================] - 49s 667ms/step - loss: 0.3521 - accuracy: 0.8461 - val_loss: 0.6245 - val_accuracy: 0.7347\n",
      "Epoch 9/20\n",
      "74/74 [==============================] - 51s 689ms/step - loss: 0.3498 - accuracy: 0.8333 - val_loss: 0.6205 - val_accuracy: 0.7211\n",
      "Epoch 10/20\n",
      "74/74 [==============================] - 52s 709ms/step - loss: 0.3469 - accuracy: 0.8316 - val_loss: 0.6078 - val_accuracy: 0.7347\n",
      "Epoch 11/20\n",
      "74/74 [==============================] - 53s 721ms/step - loss: 0.3423 - accuracy: 0.8457 - val_loss: 0.6197 - val_accuracy: 0.7279\n",
      "Epoch 12/20\n",
      "74/74 [==============================] - 51s 690ms/step - loss: 0.3418 - accuracy: 0.8495 - val_loss: 0.6464 - val_accuracy: 0.7160\n",
      "Epoch 13/20\n",
      "74/74 [==============================] - 51s 691ms/step - loss: 0.3337 - accuracy: 0.8512 - val_loss: 0.6490 - val_accuracy: 0.7194\n",
      "Epoch 14/20\n",
      "74/74 [==============================] - 51s 695ms/step - loss: 0.3307 - accuracy: 0.8482 - val_loss: 0.6422 - val_accuracy: 0.7160\n",
      "Epoch 15/20\n",
      "74/74 [==============================] - 50s 672ms/step - loss: 0.3559 - accuracy: 0.8350 - val_loss: 0.6599 - val_accuracy: 0.7177\n",
      "Epoch 16/20\n",
      "74/74 [==============================] - 49s 661ms/step - loss: 0.3399 - accuracy: 0.8461 - val_loss: 0.6193 - val_accuracy: 0.7194\n",
      "Epoch 17/20\n",
      "74/74 [==============================] - 50s 679ms/step - loss: 0.3395 - accuracy: 0.8482 - val_loss: 0.6469 - val_accuracy: 0.7160\n",
      "Epoch 18/20\n",
      "74/74 [==============================] - 49s 668ms/step - loss: 0.3405 - accuracy: 0.8414 - val_loss: 0.6495 - val_accuracy: 0.7109\n",
      "Epoch 19/20\n",
      "74/74 [==============================] - 50s 680ms/step - loss: 0.3471 - accuracy: 0.8461 - val_loss: 0.6206 - val_accuracy: 0.7330\n",
      "Epoch 20/20\n",
      "14/74 [====>.........................] - ETA: 31s - loss: 0.3205 - accuracy: 0.8326"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs=20\n",
    "history = base_model.fit(\n",
    "  train_gen,\n",
    "  validation_data = val_gen,\n",
    "  epochs = epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.save('base_dir.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
